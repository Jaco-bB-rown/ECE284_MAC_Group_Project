{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (33): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorboardX import SummaryWriter      \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant\"\n",
    "model = VGG16_quant()\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [ 25, 35, 45]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a81c0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 5.863 (5.863)\tData 5.553 (5.553)\tLoss 2.5721 (2.5721)\tPrec 14.062% (14.062%)\n",
      "Epoch: [0][100/391]\tTime 0.025 (0.084)\tData 0.000 (0.055)\tLoss 1.8293 (2.0359)\tPrec 31.250% (25.959%)\n",
      "Epoch: [0][200/391]\tTime 0.028 (0.055)\tData 0.001 (0.028)\tLoss 1.5574 (1.8460)\tPrec 43.750% (32.043%)\n",
      "Epoch: [0][300/391]\tTime 0.024 (0.046)\tData 0.000 (0.019)\tLoss 1.3888 (1.7284)\tPrec 46.094% (36.231%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.660 (4.660)\tLoss 1.4921 (1.4921)\tPrec 50.000% (50.000%)\n",
      " * Prec 49.260% \n",
      "best acc: 49.260000\n",
      "Epoch: [1][0/391]\tTime 5.629 (5.629)\tData 5.490 (5.490)\tLoss 1.2880 (1.2880)\tPrec 52.344% (52.344%)\n",
      "Epoch: [1][100/391]\tTime 0.025 (0.082)\tData 0.000 (0.055)\tLoss 1.2660 (1.2898)\tPrec 53.125% (52.754%)\n",
      "Epoch: [1][200/391]\tTime 0.024 (0.054)\tData 0.001 (0.028)\tLoss 0.9743 (1.2367)\tPrec 61.719% (54.975%)\n",
      "Epoch: [1][300/391]\tTime 0.026 (0.045)\tData 0.000 (0.019)\tLoss 0.8644 (1.1960)\tPrec 67.969% (56.281%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.674 (4.674)\tLoss 0.9945 (0.9945)\tPrec 68.750% (68.750%)\n",
      " * Prec 61.090% \n",
      "best acc: 61.090000\n",
      "Epoch: [2][0/391]\tTime 5.720 (5.720)\tData 5.514 (5.514)\tLoss 0.9625 (0.9625)\tPrec 67.188% (67.188%)\n",
      "Epoch: [2][100/391]\tTime 0.024 (0.084)\tData 0.001 (0.055)\tLoss 0.8907 (1.0158)\tPrec 67.188% (63.451%)\n",
      "Epoch: [2][200/391]\tTime 0.026 (0.055)\tData 0.001 (0.028)\tLoss 1.0167 (0.9989)\tPrec 65.625% (64.475%)\n",
      "Epoch: [2][300/391]\tTime 0.026 (0.045)\tData 0.000 (0.019)\tLoss 0.6865 (0.9782)\tPrec 77.344% (65.218%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.616 (4.616)\tLoss 0.7411 (0.7411)\tPrec 76.562% (76.562%)\n",
      " * Prec 69.540% \n",
      "best acc: 69.540000\n",
      "Epoch: [3][0/391]\tTime 5.584 (5.584)\tData 5.472 (5.472)\tLoss 0.7382 (0.7382)\tPrec 72.656% (72.656%)\n",
      "Epoch: [3][100/391]\tTime 0.026 (0.084)\tData 0.000 (0.054)\tLoss 0.8220 (0.8526)\tPrec 73.438% (70.150%)\n",
      "Epoch: [3][200/391]\tTime 0.026 (0.055)\tData 0.001 (0.028)\tLoss 0.8683 (0.8449)\tPrec 71.094% (70.522%)\n",
      "Epoch: [3][300/391]\tTime 0.027 (0.045)\tData 0.000 (0.019)\tLoss 0.5683 (0.8388)\tPrec 77.344% (70.642%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.662 (4.662)\tLoss 0.9043 (0.9043)\tPrec 66.406% (66.406%)\n",
      " * Prec 67.940% \n",
      "best acc: 69.540000\n",
      "Epoch: [4][0/391]\tTime 5.655 (5.655)\tData 5.482 (5.482)\tLoss 0.6578 (0.6578)\tPrec 77.344% (77.344%)\n",
      "Epoch: [4][100/391]\tTime 0.027 (0.083)\tData 0.001 (0.055)\tLoss 0.7861 (0.7683)\tPrec 72.656% (73.677%)\n",
      "Epoch: [4][200/391]\tTime 0.025 (0.054)\tData 0.000 (0.028)\tLoss 0.6359 (0.7594)\tPrec 78.125% (73.900%)\n",
      "Epoch: [4][300/391]\tTime 0.024 (0.045)\tData 0.000 (0.019)\tLoss 0.9121 (0.7548)\tPrec 64.062% (74.151%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.619 (4.619)\tLoss 0.6712 (0.6712)\tPrec 79.688% (79.688%)\n",
      " * Prec 72.750% \n",
      "best acc: 72.750000\n",
      "Epoch: [5][0/391]\tTime 5.651 (5.651)\tData 5.489 (5.489)\tLoss 0.8785 (0.8785)\tPrec 67.969% (67.969%)\n",
      "Epoch: [5][100/391]\tTime 0.025 (0.083)\tData 0.001 (0.055)\tLoss 0.7317 (0.7076)\tPrec 74.219% (75.526%)\n",
      "Epoch: [5][200/391]\tTime 0.026 (0.055)\tData 0.001 (0.028)\tLoss 0.6194 (0.6942)\tPrec 80.469% (76.108%)\n",
      "Epoch: [5][300/391]\tTime 0.026 (0.046)\tData 0.001 (0.019)\tLoss 0.6679 (0.6948)\tPrec 80.469% (76.098%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.626 (4.626)\tLoss 0.7003 (0.7003)\tPrec 73.438% (73.438%)\n",
      " * Prec 73.020% \n",
      "best acc: 73.020000\n",
      "Epoch: [6][0/391]\tTime 5.664 (5.664)\tData 5.499 (5.499)\tLoss 0.6215 (0.6215)\tPrec 80.469% (80.469%)\n",
      "Epoch: [6][100/391]\tTime 0.026 (0.082)\tData 0.000 (0.055)\tLoss 0.6276 (0.6431)\tPrec 77.344% (78.086%)\n",
      "Epoch: [6][200/391]\tTime 0.027 (0.054)\tData 0.000 (0.028)\tLoss 0.6314 (0.6454)\tPrec 78.906% (77.830%)\n",
      "Epoch: [6][300/391]\tTime 0.027 (0.045)\tData 0.000 (0.019)\tLoss 0.5319 (0.6425)\tPrec 82.031% (77.868%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.659 (4.659)\tLoss 0.7790 (0.7790)\tPrec 74.219% (74.219%)\n",
      " * Prec 71.520% \n",
      "best acc: 73.020000\n",
      "Epoch: [7][0/391]\tTime 5.629 (5.629)\tData 5.502 (5.502)\tLoss 0.6635 (0.6635)\tPrec 79.688% (79.688%)\n",
      "Epoch: [7][100/391]\tTime 0.029 (0.084)\tData 0.000 (0.055)\tLoss 0.7086 (0.6111)\tPrec 77.344% (79.525%)\n",
      "Epoch: [7][200/391]\tTime 0.025 (0.055)\tData 0.001 (0.028)\tLoss 0.6095 (0.6045)\tPrec 82.031% (79.516%)\n",
      "Epoch: [7][300/391]\tTime 0.024 (0.046)\tData 0.000 (0.019)\tLoss 0.5005 (0.6024)\tPrec 81.250% (79.537%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.653 (4.653)\tLoss 0.6920 (0.6920)\tPrec 76.562% (76.562%)\n",
      " * Prec 78.030% \n",
      "best acc: 78.030000\n",
      "Epoch: [8][0/391]\tTime 5.605 (5.605)\tData 5.468 (5.468)\tLoss 0.6309 (0.6309)\tPrec 75.000% (75.000%)\n",
      "Epoch: [8][100/391]\tTime 0.028 (0.082)\tData 0.000 (0.055)\tLoss 0.5327 (0.5633)\tPrec 82.812% (80.500%)\n",
      "Epoch: [8][200/391]\tTime 0.026 (0.054)\tData 0.001 (0.028)\tLoss 0.5718 (0.5587)\tPrec 81.250% (80.826%)\n",
      "Epoch: [8][300/391]\tTime 0.026 (0.045)\tData 0.000 (0.019)\tLoss 0.6492 (0.5621)\tPrec 78.906% (80.804%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.656 (4.656)\tLoss 0.5332 (0.5332)\tPrec 81.250% (81.250%)\n",
      " * Prec 77.830% \n",
      "best acc: 78.030000\n",
      "Epoch: [9][0/391]\tTime 5.621 (5.621)\tData 5.490 (5.490)\tLoss 0.6004 (0.6004)\tPrec 82.031% (82.031%)\n",
      "Epoch: [9][100/391]\tTime 0.025 (0.084)\tData 0.000 (0.055)\tLoss 0.4873 (0.5325)\tPrec 81.250% (82.054%)\n",
      "Epoch: [9][200/391]\tTime 0.025 (0.055)\tData 0.000 (0.028)\tLoss 0.5135 (0.5430)\tPrec 81.250% (81.382%)\n",
      "Epoch: [9][300/391]\tTime 0.024 (0.046)\tData 0.000 (0.019)\tLoss 0.5449 (0.5431)\tPrec 82.812% (81.486%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.678 (4.678)\tLoss 0.6746 (0.6746)\tPrec 75.781% (75.781%)\n",
      " * Prec 76.270% \n",
      "best acc: 78.030000\n",
      "Epoch: [10][0/391]\tTime 5.589 (5.589)\tData 5.485 (5.485)\tLoss 0.5205 (0.5205)\tPrec 78.125% (78.125%)\n",
      "Epoch: [10][100/391]\tTime 0.025 (0.082)\tData 0.000 (0.055)\tLoss 0.4376 (0.5109)\tPrec 84.375% (82.766%)\n",
      "Epoch: [10][200/391]\tTime 0.025 (0.054)\tData 0.001 (0.028)\tLoss 0.5638 (0.5161)\tPrec 80.469% (82.568%)\n",
      "Epoch: [10][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.019)\tLoss 0.5610 (0.5079)\tPrec 83.594% (82.745%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.604 (4.604)\tLoss 0.5090 (0.5090)\tPrec 81.250% (81.250%)\n",
      " * Prec 81.800% \n",
      "best acc: 81.800000\n",
      "Epoch: [11][0/391]\tTime 5.546 (5.546)\tData 5.458 (5.458)\tLoss 0.3143 (0.3143)\tPrec 91.406% (91.406%)\n",
      "Epoch: [11][100/391]\tTime 0.027 (0.082)\tData 0.000 (0.054)\tLoss 0.6155 (0.4780)\tPrec 78.125% (83.694%)\n",
      "Epoch: [11][200/391]\tTime 0.025 (0.054)\tData 0.000 (0.028)\tLoss 0.4446 (0.4780)\tPrec 89.062% (83.776%)\n",
      "Epoch: [11][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.019)\tLoss 0.4906 (0.4820)\tPrec 80.469% (83.734%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.585 (4.585)\tLoss 0.4928 (0.4928)\tPrec 85.156% (85.156%)\n",
      " * Prec 80.810% \n",
      "best acc: 81.800000\n",
      "Epoch: [12][0/391]\tTime 5.571 (5.571)\tData 5.454 (5.454)\tLoss 0.4376 (0.4376)\tPrec 87.500% (87.500%)\n",
      "Epoch: [12][100/391]\tTime 0.025 (0.082)\tData 0.000 (0.054)\tLoss 0.5426 (0.4619)\tPrec 82.031% (84.530%)\n",
      "Epoch: [12][200/391]\tTime 0.025 (0.054)\tData 0.000 (0.027)\tLoss 0.4228 (0.4603)\tPrec 82.031% (84.418%)\n",
      "Epoch: [12][300/391]\tTime 0.036 (0.044)\tData 0.001 (0.018)\tLoss 0.4298 (0.4553)\tPrec 85.156% (84.539%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.610 (4.610)\tLoss 0.5507 (0.5507)\tPrec 83.594% (83.594%)\n",
      " * Prec 81.440% \n",
      "best acc: 81.800000\n",
      "Epoch: [13][0/391]\tTime 5.485 (5.485)\tData 5.442 (5.442)\tLoss 0.5922 (0.5922)\tPrec 82.812% (82.812%)\n",
      "Epoch: [13][100/391]\tTime 0.032 (0.082)\tData 0.000 (0.054)\tLoss 0.6337 (0.4317)\tPrec 78.906% (85.063%)\n",
      "Epoch: [13][200/391]\tTime 0.032 (0.054)\tData 0.001 (0.027)\tLoss 0.4027 (0.4382)\tPrec 89.844% (84.993%)\n",
      "Epoch: [13][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.018)\tLoss 0.4814 (0.4443)\tPrec 82.031% (84.775%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.568 (4.568)\tLoss 0.6198 (0.6198)\tPrec 81.250% (81.250%)\n",
      " * Prec 79.940% \n",
      "best acc: 81.800000\n",
      "Epoch: [14][0/391]\tTime 5.537 (5.537)\tData 5.454 (5.454)\tLoss 0.4641 (0.4641)\tPrec 84.375% (84.375%)\n",
      "Epoch: [14][100/391]\tTime 0.024 (0.083)\tData 0.000 (0.054)\tLoss 0.5266 (0.4179)\tPrec 79.688% (85.852%)\n",
      "Epoch: [14][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.4978 (0.4172)\tPrec 80.469% (85.930%)\n",
      "Epoch: [14][300/391]\tTime 0.032 (0.045)\tData 0.000 (0.018)\tLoss 0.3610 (0.4190)\tPrec 87.500% (85.834%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.569 (4.569)\tLoss 0.5732 (0.5732)\tPrec 80.469% (80.469%)\n",
      " * Prec 81.210% \n",
      "best acc: 81.800000\n",
      "Epoch: [15][0/391]\tTime 5.745 (5.745)\tData 5.628 (5.628)\tLoss 0.5074 (0.5074)\tPrec 83.594% (83.594%)\n",
      "Epoch: [15][100/391]\tTime 0.024 (0.085)\tData 0.001 (0.056)\tLoss 0.3436 (0.4094)\tPrec 89.844% (85.930%)\n",
      "Epoch: [15][200/391]\tTime 0.024 (0.055)\tData 0.000 (0.028)\tLoss 0.4381 (0.4076)\tPrec 86.719% (85.941%)\n",
      "Epoch: [15][300/391]\tTime 0.026 (0.046)\tData 0.000 (0.019)\tLoss 0.3697 (0.4091)\tPrec 85.938% (85.961%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.561 (4.561)\tLoss 0.4318 (0.4318)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.050% \n",
      "best acc: 83.050000\n",
      "Epoch: [16][0/391]\tTime 5.633 (5.633)\tData 5.476 (5.476)\tLoss 0.3741 (0.3741)\tPrec 85.938% (85.938%)\n",
      "Epoch: [16][100/391]\tTime 0.024 (0.084)\tData 0.000 (0.055)\tLoss 0.4036 (0.3845)\tPrec 82.031% (86.943%)\n",
      "Epoch: [16][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.3255 (0.3843)\tPrec 89.844% (86.971%)\n",
      "Epoch: [16][300/391]\tTime 0.026 (0.046)\tData 0.000 (0.019)\tLoss 0.3372 (0.3897)\tPrec 89.062% (86.786%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.651 (4.651)\tLoss 0.4151 (0.4151)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.900% \n",
      "best acc: 83.900000\n",
      "Epoch: [17][0/391]\tTime 5.593 (5.593)\tData 5.467 (5.467)\tLoss 0.2884 (0.2884)\tPrec 90.625% (90.625%)\n",
      "Epoch: [17][100/391]\tTime 0.028 (0.083)\tData 0.001 (0.054)\tLoss 0.3947 (0.3661)\tPrec 85.156% (87.485%)\n",
      "Epoch: [17][200/391]\tTime 0.025 (0.055)\tData 0.000 (0.028)\tLoss 0.3450 (0.3741)\tPrec 86.719% (87.310%)\n",
      "Epoch: [17][300/391]\tTime 0.027 (0.045)\tData 0.000 (0.019)\tLoss 0.4010 (0.3755)\tPrec 84.375% (87.243%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.699 (4.699)\tLoss 0.4704 (0.4704)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.420% \n",
      "best acc: 84.420000\n",
      "Epoch: [18][0/391]\tTime 5.606 (5.606)\tData 5.517 (5.517)\tLoss 0.1968 (0.1968)\tPrec 95.312% (95.312%)\n",
      "Epoch: [18][100/391]\tTime 0.024 (0.082)\tData 0.000 (0.055)\tLoss 0.3878 (0.3555)\tPrec 86.719% (87.856%)\n",
      "Epoch: [18][200/391]\tTime 0.024 (0.054)\tData 0.000 (0.028)\tLoss 0.3243 (0.3601)\tPrec 89.844% (87.620%)\n",
      "Epoch: [18][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.019)\tLoss 0.3002 (0.3624)\tPrec 89.844% (87.575%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.633 (4.633)\tLoss 0.3827 (0.3827)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.940% \n",
      "best acc: 84.940000\n",
      "Epoch: [19][0/391]\tTime 5.554 (5.554)\tData 5.465 (5.465)\tLoss 0.2112 (0.2112)\tPrec 90.625% (90.625%)\n",
      "Epoch: [19][100/391]\tTime 0.028 (0.082)\tData 0.000 (0.054)\tLoss 0.3426 (0.3353)\tPrec 87.500% (88.691%)\n",
      "Epoch: [19][200/391]\tTime 0.024 (0.054)\tData 0.001 (0.028)\tLoss 0.2369 (0.3388)\tPrec 89.844% (88.441%)\n",
      "Epoch: [19][300/391]\tTime 0.026 (0.045)\tData 0.001 (0.019)\tLoss 0.3439 (0.3441)\tPrec 89.062% (88.294%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.608 (4.608)\tLoss 0.3733 (0.3733)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.490% \n",
      "best acc: 84.940000\n",
      "Epoch: [20][0/391]\tTime 5.569 (5.569)\tData 5.457 (5.457)\tLoss 0.3496 (0.3496)\tPrec 87.500% (87.500%)\n",
      "Epoch: [20][100/391]\tTime 0.024 (0.081)\tData 0.000 (0.054)\tLoss 0.3630 (0.3223)\tPrec 88.281% (88.792%)\n",
      "Epoch: [20][200/391]\tTime 0.025 (0.053)\tData 0.000 (0.027)\tLoss 0.2449 (0.3327)\tPrec 92.188% (88.631%)\n",
      "Epoch: [20][300/391]\tTime 0.025 (0.044)\tData 0.000 (0.018)\tLoss 0.3194 (0.3352)\tPrec 86.719% (88.556%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.597 (4.597)\tLoss 0.4110 (0.4110)\tPrec 82.812% (82.812%)\n",
      " * Prec 84.480% \n",
      "best acc: 84.940000\n",
      "Epoch: [21][0/391]\tTime 5.539 (5.539)\tData 5.450 (5.450)\tLoss 0.2394 (0.2394)\tPrec 93.750% (93.750%)\n",
      "Epoch: [21][100/391]\tTime 0.025 (0.083)\tData 0.000 (0.054)\tLoss 0.2526 (0.3126)\tPrec 91.406% (89.472%)\n",
      "Epoch: [21][200/391]\tTime 0.026 (0.055)\tData 0.002 (0.027)\tLoss 0.3472 (0.3192)\tPrec 88.281% (89.234%)\n",
      "Epoch: [21][300/391]\tTime 0.026 (0.045)\tData 0.002 (0.018)\tLoss 0.3207 (0.3237)\tPrec 89.844% (89.003%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.721 (4.721)\tLoss 0.4666 (0.4666)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.560% \n",
      "best acc: 84.940000\n",
      "Epoch: [22][0/391]\tTime 5.511 (5.511)\tData 5.409 (5.409)\tLoss 0.4294 (0.4294)\tPrec 86.719% (86.719%)\n",
      "Epoch: [22][100/391]\tTime 0.024 (0.081)\tData 0.000 (0.054)\tLoss 0.3114 (0.3029)\tPrec 92.188% (89.743%)\n",
      "Epoch: [22][200/391]\tTime 0.025 (0.053)\tData 0.000 (0.027)\tLoss 0.2447 (0.3151)\tPrec 92.969% (89.241%)\n",
      "Epoch: [22][300/391]\tTime 0.024 (0.044)\tData 0.000 (0.018)\tLoss 0.4241 (0.3128)\tPrec 87.500% (89.358%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.586 (4.586)\tLoss 0.3598 (0.3598)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.880% \n",
      "best acc: 85.880000\n",
      "Epoch: [23][0/391]\tTime 5.523 (5.523)\tData 5.426 (5.426)\tLoss 0.3919 (0.3919)\tPrec 82.812% (82.812%)\n",
      "Epoch: [23][100/391]\tTime 0.032 (0.083)\tData 0.000 (0.054)\tLoss 0.2846 (0.3154)\tPrec 89.062% (89.155%)\n",
      "Epoch: [23][200/391]\tTime 0.031 (0.054)\tData 0.000 (0.027)\tLoss 0.3286 (0.3043)\tPrec 89.062% (89.785%)\n",
      "Epoch: [23][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.018)\tLoss 0.2621 (0.3047)\tPrec 92.188% (89.743%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.609 (4.609)\tLoss 0.3764 (0.3764)\tPrec 89.062% (89.062%)\n",
      " * Prec 84.220% \n",
      "best acc: 85.880000\n",
      "Epoch: [24][0/391]\tTime 5.525 (5.525)\tData 5.434 (5.434)\tLoss 0.2253 (0.2253)\tPrec 93.750% (93.750%)\n",
      "Epoch: [24][100/391]\tTime 0.026 (0.081)\tData 0.001 (0.054)\tLoss 0.3609 (0.2790)\tPrec 90.625% (90.501%)\n",
      "Epoch: [24][200/391]\tTime 0.024 (0.053)\tData 0.001 (0.027)\tLoss 0.1358 (0.2891)\tPrec 95.312% (90.162%)\n",
      "Epoch: [24][300/391]\tTime 0.026 (0.044)\tData 0.002 (0.018)\tLoss 0.3243 (0.2948)\tPrec 86.719% (89.945%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.607 (4.607)\tLoss 0.3944 (0.3944)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.140% \n",
      "best acc: 85.880000\n",
      "Epoch: [25][0/391]\tTime 5.487 (5.487)\tData 5.432 (5.432)\tLoss 0.2521 (0.2521)\tPrec 90.625% (90.625%)\n",
      "Epoch: [25][100/391]\tTime 0.025 (0.081)\tData 0.001 (0.054)\tLoss 0.2566 (0.2341)\tPrec 89.062% (91.994%)\n",
      "Epoch: [25][200/391]\tTime 0.026 (0.054)\tData 0.000 (0.027)\tLoss 0.1632 (0.2180)\tPrec 94.531% (92.530%)\n",
      "Epoch: [25][300/391]\tTime 0.024 (0.045)\tData 0.001 (0.018)\tLoss 0.1543 (0.2100)\tPrec 94.531% (92.784%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.592 (4.592)\tLoss 0.2870 (0.2870)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.870% \n",
      "best acc: 88.870000\n",
      "Epoch: [26][0/391]\tTime 5.496 (5.496)\tData 5.400 (5.400)\tLoss 0.2420 (0.2420)\tPrec 93.750% (93.750%)\n",
      "Epoch: [26][100/391]\tTime 0.024 (0.081)\tData 0.000 (0.054)\tLoss 0.1351 (0.1767)\tPrec 95.312% (94.044%)\n",
      "Epoch: [26][200/391]\tTime 0.025 (0.054)\tData 0.000 (0.027)\tLoss 0.1780 (0.1800)\tPrec 93.750% (93.956%)\n",
      "Epoch: [26][300/391]\tTime 0.023 (0.044)\tData 0.000 (0.018)\tLoss 0.2366 (0.1794)\tPrec 92.188% (93.898%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.582 (4.582)\tLoss 0.2360 (0.2360)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.990% \n",
      "best acc: 88.990000\n",
      "Epoch: [27][0/391]\tTime 5.481 (5.481)\tData 5.399 (5.399)\tLoss 0.1461 (0.1461)\tPrec 93.750% (93.750%)\n",
      "Epoch: [27][100/391]\tTime 0.032 (0.082)\tData 0.000 (0.054)\tLoss 0.2414 (0.1823)\tPrec 91.406% (93.866%)\n",
      "Epoch: [27][200/391]\tTime 0.024 (0.054)\tData 0.000 (0.027)\tLoss 0.1470 (0.1732)\tPrec 93.750% (94.170%)\n",
      "Epoch: [27][300/391]\tTime 0.025 (0.044)\tData 0.001 (0.018)\tLoss 0.1217 (0.1726)\tPrec 95.312% (94.126%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.588 (4.588)\tLoss 0.2135 (0.2135)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.410% \n",
      "best acc: 89.410000\n",
      "Epoch: [28][0/391]\tTime 5.534 (5.534)\tData 5.441 (5.441)\tLoss 0.0900 (0.0900)\tPrec 97.656% (97.656%)\n",
      "Epoch: [28][100/391]\tTime 0.024 (0.082)\tData 0.000 (0.054)\tLoss 0.2175 (0.1634)\tPrec 90.625% (94.547%)\n",
      "Epoch: [28][200/391]\tTime 0.031 (0.054)\tData 0.000 (0.027)\tLoss 0.1952 (0.1652)\tPrec 92.188% (94.469%)\n",
      "Epoch: [28][300/391]\tTime 0.025 (0.044)\tData 0.000 (0.018)\tLoss 0.2762 (0.1632)\tPrec 91.406% (94.523%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.596 (4.596)\tLoss 0.2273 (0.2273)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.440% \n",
      "best acc: 89.440000\n",
      "Epoch: [29][0/391]\tTime 5.528 (5.528)\tData 5.436 (5.436)\tLoss 0.1451 (0.1451)\tPrec 94.531% (94.531%)\n",
      "Epoch: [29][100/391]\tTime 0.026 (0.082)\tData 0.000 (0.054)\tLoss 0.2586 (0.1602)\tPrec 89.844% (94.307%)\n",
      "Epoch: [29][200/391]\tTime 0.025 (0.054)\tData 0.000 (0.027)\tLoss 0.2181 (0.1592)\tPrec 93.750% (94.531%)\n",
      "Epoch: [29][300/391]\tTime 0.025 (0.045)\tData 0.001 (0.018)\tLoss 0.1802 (0.1566)\tPrec 95.312% (94.578%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.597 (4.597)\tLoss 0.1947 (0.1947)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.490% \n",
      "best acc: 89.490000\n",
      "Epoch: [30][0/391]\tTime 5.547 (5.547)\tData 5.441 (5.441)\tLoss 0.2836 (0.2836)\tPrec 91.406% (91.406%)\n",
      "Epoch: [30][100/391]\tTime 0.024 (0.082)\tData 0.001 (0.054)\tLoss 0.1484 (0.1515)\tPrec 95.312% (94.756%)\n",
      "Epoch: [30][200/391]\tTime 0.024 (0.054)\tData 0.000 (0.027)\tLoss 0.1843 (0.1537)\tPrec 90.625% (94.671%)\n",
      "Epoch: [30][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.018)\tLoss 0.2231 (0.1537)\tPrec 92.188% (94.705%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.596 (4.596)\tLoss 0.2914 (0.2914)\tPrec 89.062% (89.062%)\n",
      " * Prec 89.440% \n",
      "best acc: 89.490000\n",
      "Epoch: [31][0/391]\tTime 5.508 (5.508)\tData 5.423 (5.423)\tLoss 0.1558 (0.1558)\tPrec 92.969% (92.969%)\n",
      "Epoch: [31][100/391]\tTime 0.024 (0.082)\tData 0.000 (0.054)\tLoss 0.1273 (0.1556)\tPrec 94.531% (94.771%)\n",
      "Epoch: [31][200/391]\tTime 0.032 (0.054)\tData 0.000 (0.027)\tLoss 0.1104 (0.1518)\tPrec 96.875% (94.947%)\n",
      "Epoch: [31][300/391]\tTime 0.024 (0.044)\tData 0.000 (0.018)\tLoss 0.2027 (0.1505)\tPrec 93.750% (94.923%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.582 (4.582)\tLoss 0.2300 (0.2300)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.400% \n",
      "best acc: 89.490000\n",
      "Epoch: [32][0/391]\tTime 5.534 (5.534)\tData 5.442 (5.442)\tLoss 0.0994 (0.0994)\tPrec 96.094% (96.094%)\n",
      "Epoch: [32][100/391]\tTime 0.032 (0.082)\tData 0.001 (0.054)\tLoss 0.2171 (0.1393)\tPrec 92.969% (95.312%)\n",
      "Epoch: [32][200/391]\tTime 0.025 (0.054)\tData 0.000 (0.027)\tLoss 0.0867 (0.1431)\tPrec 98.438% (95.149%)\n",
      "Epoch: [32][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.018)\tLoss 0.1622 (0.1443)\tPrec 92.188% (95.081%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.586 (4.586)\tLoss 0.2538 (0.2538)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.410% \n",
      "best acc: 89.490000\n",
      "Epoch: [33][0/391]\tTime 5.518 (5.518)\tData 5.422 (5.422)\tLoss 0.1496 (0.1496)\tPrec 94.531% (94.531%)\n",
      "Epoch: [33][100/391]\tTime 0.032 (0.082)\tData 0.001 (0.054)\tLoss 0.1446 (0.1361)\tPrec 96.094% (95.483%)\n",
      "Epoch: [33][200/391]\tTime 0.025 (0.054)\tData 0.001 (0.027)\tLoss 0.1757 (0.1397)\tPrec 93.750% (95.320%)\n",
      "Epoch: [33][300/391]\tTime 0.026 (0.045)\tData 0.001 (0.018)\tLoss 0.1445 (0.1418)\tPrec 96.875% (95.258%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.606 (4.606)\tLoss 0.2681 (0.2681)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.280% \n",
      "best acc: 89.490000\n",
      "Epoch: [34][0/391]\tTime 5.466 (5.466)\tData 5.424 (5.424)\tLoss 0.1492 (0.1492)\tPrec 95.312% (95.312%)\n",
      "Epoch: [34][100/391]\tTime 0.024 (0.083)\tData 0.000 (0.054)\tLoss 0.0958 (0.1358)\tPrec 96.094% (95.266%)\n",
      "Epoch: [34][200/391]\tTime 0.024 (0.054)\tData 0.000 (0.027)\tLoss 0.1246 (0.1379)\tPrec 94.531% (95.243%)\n",
      "Epoch: [34][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.018)\tLoss 0.1222 (0.1388)\tPrec 96.094% (95.178%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.624 (4.624)\tLoss 0.2568 (0.2568)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.590% \n",
      "best acc: 89.590000\n",
      "Epoch: [35][0/391]\tTime 5.682 (5.682)\tData 5.574 (5.574)\tLoss 0.1028 (0.1028)\tPrec 95.312% (95.312%)\n",
      "Epoch: [35][100/391]\tTime 0.025 (0.084)\tData 0.001 (0.056)\tLoss 0.0866 (0.1280)\tPrec 96.875% (95.421%)\n",
      "Epoch: [35][200/391]\tTime 0.025 (0.055)\tData 0.001 (0.028)\tLoss 0.1832 (0.1305)\tPrec 94.531% (95.410%)\n",
      "Epoch: [35][300/391]\tTime 0.025 (0.045)\tData 0.001 (0.019)\tLoss 0.1119 (0.1301)\tPrec 96.875% (95.434%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.606 (4.606)\tLoss 0.2392 (0.2392)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.740% \n",
      "best acc: 89.740000\n",
      "Epoch: [36][0/391]\tTime 5.678 (5.678)\tData 5.583 (5.583)\tLoss 0.2488 (0.2488)\tPrec 93.750% (93.750%)\n",
      "Epoch: [36][100/391]\tTime 0.027 (0.083)\tData 0.000 (0.056)\tLoss 0.1348 (0.1242)\tPrec 94.531% (95.746%)\n",
      "Epoch: [36][200/391]\tTime 0.024 (0.054)\tData 0.000 (0.028)\tLoss 0.1276 (0.1228)\tPrec 94.531% (95.841%)\n",
      "Epoch: [36][300/391]\tTime 0.024 (0.045)\tData 0.000 (0.019)\tLoss 0.1063 (0.1230)\tPrec 96.875% (95.813%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.599 (4.599)\tLoss 0.2353 (0.2353)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.900% \n",
      "best acc: 89.900000\n",
      "Epoch: [37][0/391]\tTime 5.688 (5.688)\tData 5.572 (5.572)\tLoss 0.0981 (0.0981)\tPrec 96.094% (96.094%)\n",
      "Epoch: [37][100/391]\tTime 0.026 (0.082)\tData 0.001 (0.056)\tLoss 0.1074 (0.1278)\tPrec 96.094% (95.699%)\n",
      "Epoch: [37][200/391]\tTime 0.027 (0.054)\tData 0.000 (0.028)\tLoss 0.1064 (0.1255)\tPrec 96.094% (95.775%)\n",
      "Epoch: [37][300/391]\tTime 0.025 (0.045)\tData 0.001 (0.019)\tLoss 0.1201 (0.1232)\tPrec 92.969% (95.850%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.541 (4.541)\tLoss 0.2273 (0.2273)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.760% \n",
      "best acc: 89.900000\n",
      "Epoch: [38][0/391]\tTime 5.632 (5.632)\tData 5.543 (5.543)\tLoss 0.1884 (0.1884)\tPrec 95.312% (95.312%)\n",
      "Epoch: [38][100/391]\tTime 0.026 (0.083)\tData 0.000 (0.055)\tLoss 0.1372 (0.1268)\tPrec 96.094% (95.521%)\n",
      "Epoch: [38][200/391]\tTime 0.025 (0.054)\tData 0.001 (0.028)\tLoss 0.0733 (0.1209)\tPrec 97.656% (95.787%)\n",
      "Epoch: [38][300/391]\tTime 0.024 (0.045)\tData 0.000 (0.019)\tLoss 0.1269 (0.1181)\tPrec 96.094% (95.925%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.619 (4.619)\tLoss 0.2630 (0.2630)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.810% \n",
      "best acc: 89.900000\n",
      "Epoch: [39][0/391]\tTime 5.631 (5.631)\tData 5.534 (5.534)\tLoss 0.1603 (0.1603)\tPrec 94.531% (94.531%)\n",
      "Epoch: [39][100/391]\tTime 0.025 (0.082)\tData 0.000 (0.055)\tLoss 0.0723 (0.1157)\tPrec 96.875% (95.970%)\n",
      "Epoch: [39][200/391]\tTime 0.026 (0.054)\tData 0.000 (0.028)\tLoss 0.1641 (0.1203)\tPrec 93.750% (95.888%)\n",
      "Epoch: [39][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.019)\tLoss 0.1847 (0.1191)\tPrec 92.969% (95.933%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.588 (4.588)\tLoss 0.2579 (0.2579)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.640% \n",
      "best acc: 89.900000\n",
      "Epoch: [40][0/391]\tTime 5.671 (5.671)\tData 5.594 (5.594)\tLoss 0.1359 (0.1359)\tPrec 96.875% (96.875%)\n",
      "Epoch: [40][100/391]\tTime 0.026 (0.083)\tData 0.001 (0.056)\tLoss 0.0681 (0.1232)\tPrec 96.875% (95.808%)\n",
      "Epoch: [40][200/391]\tTime 0.024 (0.055)\tData 0.000 (0.028)\tLoss 0.0951 (0.1196)\tPrec 95.312% (95.907%)\n",
      "Epoch: [40][300/391]\tTime 0.027 (0.045)\tData 0.001 (0.019)\tLoss 0.1214 (0.1182)\tPrec 94.531% (95.961%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.625 (4.625)\tLoss 0.2710 (0.2710)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.680% \n",
      "best acc: 89.900000\n",
      "Epoch: [41][0/391]\tTime 5.733 (5.733)\tData 5.586 (5.586)\tLoss 0.1356 (0.1356)\tPrec 93.750% (93.750%)\n",
      "Epoch: [41][100/391]\tTime 0.027 (0.084)\tData 0.000 (0.056)\tLoss 0.0996 (0.1172)\tPrec 96.875% (95.955%)\n",
      "Epoch: [41][200/391]\tTime 0.026 (0.055)\tData 0.001 (0.028)\tLoss 0.1124 (0.1172)\tPrec 96.875% (95.950%)\n",
      "Epoch: [41][300/391]\tTime 0.026 (0.046)\tData 0.000 (0.019)\tLoss 0.0787 (0.1185)\tPrec 97.656% (95.956%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.623 (4.623)\tLoss 0.1980 (0.1980)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.740% \n",
      "best acc: 89.900000\n",
      "Epoch: [42][0/391]\tTime 5.731 (5.731)\tData 5.576 (5.576)\tLoss 0.0749 (0.0749)\tPrec 96.094% (96.094%)\n",
      "Epoch: [42][100/391]\tTime 0.024 (0.084)\tData 0.000 (0.056)\tLoss 0.0914 (0.1171)\tPrec 96.875% (96.063%)\n",
      "Epoch: [42][200/391]\tTime 0.027 (0.056)\tData 0.001 (0.028)\tLoss 0.0612 (0.1149)\tPrec 97.656% (96.148%)\n",
      "Epoch: [42][300/391]\tTime 0.028 (0.046)\tData 0.000 (0.019)\tLoss 0.1129 (0.1175)\tPrec 96.094% (96.029%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.641 (4.641)\tLoss 0.2051 (0.2051)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.720% \n",
      "best acc: 89.900000\n",
      "Epoch: [43][0/391]\tTime 5.705 (5.705)\tData 5.574 (5.574)\tLoss 0.1471 (0.1471)\tPrec 96.094% (96.094%)\n",
      "Epoch: [43][100/391]\tTime 0.025 (0.084)\tData 0.000 (0.056)\tLoss 0.1017 (0.1174)\tPrec 96.094% (95.993%)\n",
      "Epoch: [43][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.1279 (0.1159)\tPrec 96.094% (96.039%)\n",
      "Epoch: [43][300/391]\tTime 0.027 (0.045)\tData 0.000 (0.019)\tLoss 0.1894 (0.1167)\tPrec 92.969% (96.065%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.642 (4.642)\tLoss 0.2742 (0.2742)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.760% \n",
      "best acc: 89.900000\n",
      "Epoch: [44][0/391]\tTime 5.669 (5.669)\tData 5.546 (5.546)\tLoss 0.0658 (0.0658)\tPrec 98.438% (98.438%)\n",
      "Epoch: [44][100/391]\tTime 0.024 (0.084)\tData 0.001 (0.055)\tLoss 0.0874 (0.1157)\tPrec 97.656% (95.962%)\n",
      "Epoch: [44][200/391]\tTime 0.033 (0.055)\tData 0.000 (0.028)\tLoss 0.0916 (0.1173)\tPrec 97.656% (95.892%)\n",
      "Epoch: [44][300/391]\tTime 0.024 (0.046)\tData 0.000 (0.019)\tLoss 0.1333 (0.1186)\tPrec 95.312% (95.819%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.624 (4.624)\tLoss 0.2804 (0.2804)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.850% \n",
      "best acc: 89.900000\n",
      "Epoch: [45][0/391]\tTime 5.637 (5.637)\tData 5.523 (5.523)\tLoss 0.1041 (0.1041)\tPrec 95.312% (95.312%)\n",
      "Epoch: [45][100/391]\tTime 0.024 (0.083)\tData 0.001 (0.055)\tLoss 0.1268 (0.1146)\tPrec 95.312% (96.125%)\n",
      "Epoch: [45][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.1046 (0.1123)\tPrec 95.312% (96.156%)\n",
      "Epoch: [45][300/391]\tTime 0.026 (0.045)\tData 0.000 (0.019)\tLoss 0.0735 (0.1109)\tPrec 98.438% (96.195%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.643 (4.643)\tLoss 0.2610 (0.2610)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.750% \n",
      "best acc: 89.900000\n",
      "Epoch: [46][0/391]\tTime 5.706 (5.706)\tData 5.564 (5.564)\tLoss 0.1102 (0.1102)\tPrec 96.094% (96.094%)\n",
      "Epoch: [46][100/391]\tTime 0.034 (0.085)\tData 0.001 (0.056)\tLoss 0.0949 (0.1147)\tPrec 96.875% (96.101%)\n",
      "Epoch: [46][200/391]\tTime 0.032 (0.056)\tData 0.002 (0.028)\tLoss 0.0932 (0.1172)\tPrec 97.656% (95.997%)\n",
      "Epoch: [46][300/391]\tTime 0.024 (0.046)\tData 0.000 (0.019)\tLoss 0.0949 (0.1150)\tPrec 96.875% (96.055%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.636 (4.636)\tLoss 0.2453 (0.2453)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.870% \n",
      "best acc: 89.900000\n",
      "Epoch: [47][0/391]\tTime 5.638 (5.638)\tData 5.533 (5.533)\tLoss 0.1128 (0.1128)\tPrec 96.875% (96.875%)\n",
      "Epoch: [47][100/391]\tTime 0.025 (0.084)\tData 0.001 (0.055)\tLoss 0.1115 (0.1133)\tPrec 96.094% (96.140%)\n",
      "Epoch: [47][200/391]\tTime 0.025 (0.055)\tData 0.000 (0.028)\tLoss 0.1452 (0.1157)\tPrec 96.094% (96.024%)\n",
      "Epoch: [47][300/391]\tTime 0.027 (0.046)\tData 0.001 (0.019)\tLoss 0.1213 (0.1158)\tPrec 96.094% (96.000%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.636 (4.636)\tLoss 0.2531 (0.2531)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.630% \n",
      "best acc: 89.900000\n",
      "Epoch: [48][0/391]\tTime 5.721 (5.721)\tData 5.587 (5.587)\tLoss 0.1175 (0.1175)\tPrec 95.312% (95.312%)\n",
      "Epoch: [48][100/391]\tTime 0.025 (0.085)\tData 0.001 (0.056)\tLoss 0.1056 (0.1169)\tPrec 96.094% (96.071%)\n",
      "Epoch: [48][200/391]\tTime 0.026 (0.056)\tData 0.001 (0.028)\tLoss 0.1259 (0.1150)\tPrec 95.312% (96.133%)\n",
      "Epoch: [48][300/391]\tTime 0.034 (0.046)\tData 0.000 (0.019)\tLoss 0.1620 (0.1176)\tPrec 91.406% (96.031%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.640 (4.640)\tLoss 0.2441 (0.2441)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.770% \n",
      "best acc: 89.900000\n",
      "Epoch: [49][0/391]\tTime 5.726 (5.726)\tData 5.588 (5.588)\tLoss 0.0615 (0.0615)\tPrec 98.438% (98.438%)\n",
      "Epoch: [49][100/391]\tTime 0.027 (0.085)\tData 0.001 (0.056)\tLoss 0.1031 (0.1139)\tPrec 98.438% (96.171%)\n",
      "Epoch: [49][200/391]\tTime 0.026 (0.056)\tData 0.001 (0.028)\tLoss 0.0778 (0.1190)\tPrec 97.656% (95.997%)\n",
      "Epoch: [49][300/391]\tTime 0.025 (0.046)\tData 0.000 (0.019)\tLoss 0.1900 (0.1188)\tPrec 92.969% (95.889%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.638 (4.638)\tLoss 0.2366 (0.2366)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.860% \n",
      "best acc: 89.900000\n",
      "Epoch: [50][0/391]\tTime 5.692 (5.692)\tData 5.575 (5.575)\tLoss 0.0742 (0.0742)\tPrec 96.875% (96.875%)\n",
      "Epoch: [50][100/391]\tTime 0.029 (0.084)\tData 0.001 (0.056)\tLoss 0.1390 (0.1184)\tPrec 93.750% (95.877%)\n",
      "Epoch: [50][200/391]\tTime 0.027 (0.055)\tData 0.001 (0.028)\tLoss 0.1613 (0.1162)\tPrec 96.094% (95.989%)\n",
      "Epoch: [50][300/391]\tTime 0.026 (0.045)\tData 0.001 (0.019)\tLoss 0.0472 (0.1148)\tPrec 98.438% (95.977%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.649 (4.649)\tLoss 0.2317 (0.2317)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.670% \n",
      "best acc: 89.900000\n",
      "Epoch: [51][0/391]\tTime 5.659 (5.659)\tData 5.554 (5.554)\tLoss 0.1256 (0.1256)\tPrec 92.188% (92.188%)\n",
      "Epoch: [51][100/391]\tTime 0.025 (0.085)\tData 0.001 (0.055)\tLoss 0.1118 (0.1169)\tPrec 95.312% (95.985%)\n",
      "Epoch: [51][200/391]\tTime 0.027 (0.056)\tData 0.000 (0.028)\tLoss 0.1920 (0.1157)\tPrec 92.188% (96.074%)\n",
      "Epoch: [51][300/391]\tTime 0.023 (0.046)\tData 0.000 (0.019)\tLoss 0.1367 (0.1157)\tPrec 94.531% (96.065%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.615 (4.615)\tLoss 0.2604 (0.2604)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.780% \n",
      "best acc: 89.900000\n",
      "Epoch: [52][0/391]\tTime 5.660 (5.660)\tData 5.536 (5.536)\tLoss 0.1173 (0.1173)\tPrec 94.531% (94.531%)\n",
      "Epoch: [52][100/391]\tTime 0.024 (0.084)\tData 0.000 (0.055)\tLoss 0.0405 (0.1139)\tPrec 99.219% (96.148%)\n",
      "Epoch: [52][200/391]\tTime 0.027 (0.055)\tData 0.001 (0.028)\tLoss 0.0864 (0.1168)\tPrec 96.094% (96.059%)\n",
      "Epoch: [52][300/391]\tTime 0.028 (0.046)\tData 0.000 (0.019)\tLoss 0.1835 (0.1138)\tPrec 92.969% (96.164%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.626 (4.626)\tLoss 0.2675 (0.2675)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.600% \n",
      "best acc: 89.900000\n",
      "Epoch: [53][0/391]\tTime 5.723 (5.723)\tData 5.572 (5.572)\tLoss 0.0710 (0.0710)\tPrec 96.875% (96.875%)\n",
      "Epoch: [53][100/391]\tTime 0.027 (0.083)\tData 0.000 (0.055)\tLoss 0.1716 (0.1111)\tPrec 93.750% (96.194%)\n",
      "Epoch: [53][200/391]\tTime 0.024 (0.055)\tData 0.000 (0.028)\tLoss 0.1469 (0.1147)\tPrec 95.312% (96.004%)\n",
      "Epoch: [53][300/391]\tTime 0.026 (0.046)\tData 0.000 (0.019)\tLoss 0.1451 (0.1169)\tPrec 95.312% (95.969%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.628 (4.628)\tLoss 0.2884 (0.2884)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.600% \n",
      "best acc: 89.900000\n",
      "Epoch: [54][0/391]\tTime 5.669 (5.669)\tData 5.540 (5.540)\tLoss 0.1437 (0.1437)\tPrec 94.531% (94.531%)\n",
      "Epoch: [54][100/391]\tTime 0.030 (0.085)\tData 0.001 (0.055)\tLoss 0.0801 (0.1140)\tPrec 97.656% (96.063%)\n",
      "Epoch: [54][200/391]\tTime 0.025 (0.056)\tData 0.001 (0.028)\tLoss 0.1686 (0.1131)\tPrec 93.750% (96.070%)\n",
      "Epoch: [54][300/391]\tTime 0.032 (0.046)\tData 0.000 (0.019)\tLoss 0.0974 (0.1134)\tPrec 96.094% (96.083%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.629 (4.629)\tLoss 0.2799 (0.2799)\tPrec 89.844% (89.844%)\n",
      " * Prec 90.020% \n",
      "best acc: 90.020000\n",
      "Epoch: [55][0/391]\tTime 5.708 (5.708)\tData 5.553 (5.553)\tLoss 0.1039 (0.1039)\tPrec 96.875% (96.875%)\n",
      "Epoch: [55][100/391]\tTime 0.023 (0.084)\tData 0.000 (0.055)\tLoss 0.1235 (0.1117)\tPrec 96.094% (96.225%)\n",
      "Epoch: [55][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.0606 (0.1153)\tPrec 98.438% (96.191%)\n",
      "Epoch: [55][300/391]\tTime 0.024 (0.045)\tData 0.000 (0.019)\tLoss 0.0723 (0.1148)\tPrec 97.656% (96.104%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.630 (4.630)\tLoss 0.1985 (0.1985)\tPrec 94.531% (94.531%)\n",
      " * Prec 89.910% \n",
      "best acc: 90.020000\n",
      "Epoch: [56][0/391]\tTime 5.615 (5.615)\tData 5.496 (5.496)\tLoss 0.1262 (0.1262)\tPrec 96.094% (96.094%)\n",
      "Epoch: [56][100/391]\tTime 0.024 (0.082)\tData 0.000 (0.055)\tLoss 0.0855 (0.1173)\tPrec 97.656% (96.109%)\n",
      "Epoch: [56][200/391]\tTime 0.026 (0.054)\tData 0.000 (0.028)\tLoss 0.1340 (0.1172)\tPrec 96.875% (96.070%)\n",
      "Epoch: [56][300/391]\tTime 0.030 (0.045)\tData 0.001 (0.019)\tLoss 0.1696 (0.1157)\tPrec 96.094% (96.153%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.619 (4.619)\tLoss 0.2338 (0.2338)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.820% \n",
      "best acc: 90.020000\n",
      "Epoch: [57][0/391]\tTime 5.655 (5.655)\tData 5.507 (5.507)\tLoss 0.1907 (0.1907)\tPrec 94.531% (94.531%)\n",
      "Epoch: [57][100/391]\tTime 0.024 (0.083)\tData 0.001 (0.055)\tLoss 0.1590 (0.1169)\tPrec 94.531% (96.101%)\n",
      "Epoch: [57][200/391]\tTime 0.030 (0.055)\tData 0.001 (0.028)\tLoss 0.0785 (0.1156)\tPrec 97.656% (96.074%)\n",
      "Epoch: [57][300/391]\tTime 0.030 (0.045)\tData 0.001 (0.019)\tLoss 0.1400 (0.1125)\tPrec 93.750% (96.151%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.640 (4.640)\tLoss 0.2637 (0.2637)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.980% \n",
      "best acc: 90.020000\n",
      "Epoch: [58][0/391]\tTime 5.654 (5.654)\tData 5.525 (5.525)\tLoss 0.0672 (0.0672)\tPrec 97.656% (97.656%)\n",
      "Epoch: [58][100/391]\tTime 0.026 (0.085)\tData 0.000 (0.055)\tLoss 0.1092 (0.1189)\tPrec 97.656% (95.916%)\n",
      "Epoch: [58][200/391]\tTime 0.024 (0.056)\tData 0.000 (0.028)\tLoss 0.1453 (0.1183)\tPrec 93.750% (95.965%)\n",
      "Epoch: [58][300/391]\tTime 0.027 (0.046)\tData 0.000 (0.019)\tLoss 0.1138 (0.1169)\tPrec 95.312% (95.998%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.624 (4.624)\tLoss 0.2566 (0.2566)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.780% \n",
      "best acc: 90.020000\n",
      "Epoch: [59][0/391]\tTime 5.643 (5.643)\tData 5.508 (5.508)\tLoss 0.1200 (0.1200)\tPrec 94.531% (94.531%)\n",
      "Epoch: [59][100/391]\tTime 0.027 (0.083)\tData 0.000 (0.055)\tLoss 0.1369 (0.1095)\tPrec 96.875% (96.187%)\n",
      "Epoch: [59][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.0648 (0.1126)\tPrec 97.656% (96.059%)\n",
      "Epoch: [59][300/391]\tTime 0.025 (0.046)\tData 0.000 (0.019)\tLoss 0.1418 (0.1144)\tPrec 93.750% (96.050%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.655 (4.655)\tLoss 0.2760 (0.2760)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.650% \n",
      "best acc: 90.020000\n",
      "Epoch: [60][0/391]\tTime 5.599 (5.599)\tData 5.503 (5.503)\tLoss 0.0660 (0.0660)\tPrec 97.656% (97.656%)\n",
      "Epoch: [60][100/391]\tTime 0.026 (0.084)\tData 0.001 (0.055)\tLoss 0.1384 (0.1113)\tPrec 93.750% (96.156%)\n",
      "Epoch: [60][200/391]\tTime 0.025 (0.056)\tData 0.000 (0.028)\tLoss 0.1604 (0.1097)\tPrec 94.531% (96.276%)\n",
      "Epoch: [60][300/391]\tTime 0.026 (0.046)\tData 0.000 (0.019)\tLoss 0.0566 (0.1128)\tPrec 98.438% (96.231%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.652 (4.652)\tLoss 0.2692 (0.2692)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.950% \n",
      "best acc: 90.020000\n",
      "Epoch: [61][0/391]\tTime 5.642 (5.642)\tData 5.505 (5.505)\tLoss 0.1076 (0.1076)\tPrec 95.312% (95.312%)\n",
      "Epoch: [61][100/391]\tTime 0.033 (0.083)\tData 0.000 (0.055)\tLoss 0.0751 (0.1102)\tPrec 98.438% (96.357%)\n",
      "Epoch: [61][200/391]\tTime 0.026 (0.055)\tData 0.001 (0.028)\tLoss 0.0623 (0.1116)\tPrec 97.656% (96.273%)\n",
      "Epoch: [61][300/391]\tTime 0.026 (0.045)\tData 0.000 (0.019)\tLoss 0.2701 (0.1122)\tPrec 91.406% (96.218%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.639 (4.639)\tLoss 0.2826 (0.2826)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.720% \n",
      "best acc: 90.020000\n",
      "Epoch: [62][0/391]\tTime 5.666 (5.666)\tData 5.512 (5.512)\tLoss 0.0629 (0.0629)\tPrec 98.438% (98.438%)\n",
      "Epoch: [62][100/391]\tTime 0.026 (0.084)\tData 0.000 (0.055)\tLoss 0.0582 (0.1220)\tPrec 98.438% (95.699%)\n",
      "Epoch: [62][200/391]\tTime 0.027 (0.055)\tData 0.000 (0.028)\tLoss 0.1502 (0.1170)\tPrec 95.312% (95.884%)\n",
      "Epoch: [62][300/391]\tTime 0.025 (0.046)\tData 0.000 (0.019)\tLoss 0.0622 (0.1173)\tPrec 98.438% (95.969%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.623 (4.623)\tLoss 0.2220 (0.2220)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.900% \n",
      "best acc: 90.020000\n",
      "Epoch: [63][0/391]\tTime 5.660 (5.660)\tData 5.552 (5.552)\tLoss 0.0754 (0.0754)\tPrec 97.656% (97.656%)\n",
      "Epoch: [63][100/391]\tTime 0.026 (0.084)\tData 0.001 (0.055)\tLoss 0.1522 (0.1216)\tPrec 94.531% (95.552%)\n",
      "Epoch: [63][200/391]\tTime 0.025 (0.055)\tData 0.000 (0.028)\tLoss 0.0804 (0.1192)\tPrec 97.656% (95.779%)\n",
      "Epoch: [63][300/391]\tTime 0.026 (0.046)\tData 0.001 (0.019)\tLoss 0.1042 (0.1149)\tPrec 95.312% (95.954%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.649 (4.649)\tLoss 0.2660 (0.2660)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.810% \n",
      "best acc: 90.020000\n",
      "Epoch: [64][0/391]\tTime 5.654 (5.654)\tData 5.533 (5.533)\tLoss 0.1073 (0.1073)\tPrec 96.094% (96.094%)\n",
      "Epoch: [64][100/391]\tTime 0.026 (0.084)\tData 0.001 (0.055)\tLoss 0.0713 (0.1138)\tPrec 98.438% (95.955%)\n",
      "Epoch: [64][200/391]\tTime 0.024 (0.055)\tData 0.000 (0.028)\tLoss 0.1535 (0.1178)\tPrec 96.094% (95.903%)\n",
      "Epoch: [64][300/391]\tTime 0.027 (0.046)\tData 0.000 (0.019)\tLoss 0.0833 (0.1159)\tPrec 96.875% (96.003%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.633 (4.633)\tLoss 0.2473 (0.2473)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.900% \n",
      "best acc: 90.020000\n",
      "Epoch: [65][0/391]\tTime 5.634 (5.634)\tData 5.596 (5.596)\tLoss 0.1211 (0.1211)\tPrec 95.312% (95.312%)\n",
      "Epoch: [65][100/391]\tTime 0.028 (0.085)\tData 0.001 (0.056)\tLoss 0.1221 (0.1233)\tPrec 96.094% (95.846%)\n",
      "Epoch: [65][200/391]\tTime 0.024 (0.056)\tData 0.000 (0.028)\tLoss 0.1371 (0.1149)\tPrec 94.531% (96.117%)\n",
      "Epoch: [65][300/391]\tTime 0.024 (0.046)\tData 0.000 (0.019)\tLoss 0.0937 (0.1141)\tPrec 96.875% (96.151%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.615 (4.615)\tLoss 0.2220 (0.2220)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.780% \n",
      "best acc: 90.020000\n",
      "Epoch: [66][0/391]\tTime 5.616 (5.616)\tData 5.513 (5.513)\tLoss 0.0934 (0.0934)\tPrec 96.875% (96.875%)\n",
      "Epoch: [66][100/391]\tTime 0.025 (0.084)\tData 0.001 (0.055)\tLoss 0.1249 (0.1070)\tPrec 96.094% (96.357%)\n",
      "Epoch: [66][200/391]\tTime 0.030 (0.055)\tData 0.001 (0.028)\tLoss 0.1626 (0.1128)\tPrec 94.531% (96.152%)\n",
      "Epoch: [66][300/391]\tTime 0.024 (0.045)\tData 0.000 (0.019)\tLoss 0.2106 (0.1144)\tPrec 92.188% (96.091%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.621 (4.621)\tLoss 0.2829 (0.2829)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.810% \n",
      "best acc: 90.020000\n",
      "Epoch: [67][0/391]\tTime 5.680 (5.680)\tData 5.518 (5.518)\tLoss 0.1000 (0.1000)\tPrec 97.656% (97.656%)\n",
      "Epoch: [67][100/391]\tTime 0.025 (0.083)\tData 0.000 (0.055)\tLoss 0.1488 (0.1169)\tPrec 92.969% (95.947%)\n",
      "Epoch: [67][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.0995 (0.1149)\tPrec 96.875% (96.043%)\n",
      "Epoch: [67][300/391]\tTime 0.027 (0.046)\tData 0.000 (0.019)\tLoss 0.1170 (0.1145)\tPrec 96.094% (96.091%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.658 (4.658)\tLoss 0.2721 (0.2721)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.840% \n",
      "best acc: 90.020000\n",
      "Epoch: [68][0/391]\tTime 5.662 (5.662)\tData 5.503 (5.503)\tLoss 0.0474 (0.0474)\tPrec 98.438% (98.438%)\n",
      "Epoch: [68][100/391]\tTime 0.025 (0.085)\tData 0.000 (0.055)\tLoss 0.1376 (0.1134)\tPrec 96.094% (96.194%)\n",
      "Epoch: [68][200/391]\tTime 0.025 (0.056)\tData 0.000 (0.028)\tLoss 0.1255 (0.1107)\tPrec 94.531% (96.206%)\n",
      "Epoch: [68][300/391]\tTime 0.025 (0.046)\tData 0.000 (0.019)\tLoss 0.0680 (0.1140)\tPrec 98.438% (96.068%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.644 (4.644)\tLoss 0.2354 (0.2354)\tPrec 90.625% (90.625%)\n",
      " * Prec 90.190% \n",
      "best acc: 90.190000\n",
      "Epoch: [69][0/391]\tTime 5.885 (5.885)\tData 5.764 (5.764)\tLoss 0.0752 (0.0752)\tPrec 97.656% (97.656%)\n",
      "Epoch: [69][100/391]\tTime 0.026 (0.087)\tData 0.001 (0.057)\tLoss 0.1450 (0.1189)\tPrec 94.531% (95.854%)\n",
      "Epoch: [69][200/391]\tTime 0.026 (0.057)\tData 0.001 (0.029)\tLoss 0.1353 (0.1124)\tPrec 95.312% (96.144%)\n",
      "Epoch: [69][300/391]\tTime 0.027 (0.047)\tData 0.000 (0.020)\tLoss 0.1048 (0.1128)\tPrec 96.094% (96.115%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.660 (4.660)\tLoss 0.2565 (0.2565)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.890% \n",
      "best acc: 90.190000\n",
      "Epoch: [70][0/391]\tTime 5.782 (5.782)\tData 5.650 (5.650)\tLoss 0.1906 (0.1906)\tPrec 95.312% (95.312%)\n",
      "Epoch: [70][100/391]\tTime 0.027 (0.086)\tData 0.000 (0.056)\tLoss 0.1586 (0.1191)\tPrec 95.312% (95.955%)\n",
      "Epoch: [70][200/391]\tTime 0.025 (0.056)\tData 0.000 (0.028)\tLoss 0.1667 (0.1106)\tPrec 96.094% (96.234%)\n",
      "Epoch: [70][300/391]\tTime 0.026 (0.046)\tData 0.000 (0.019)\tLoss 0.2070 (0.1121)\tPrec 95.312% (96.208%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.616 (4.616)\tLoss 0.2307 (0.2307)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.770% \n",
      "best acc: 90.190000\n",
      "Epoch: [71][0/391]\tTime 5.655 (5.655)\tData 5.496 (5.496)\tLoss 0.1397 (0.1397)\tPrec 95.312% (95.312%)\n",
      "Epoch: [71][100/391]\tTime 0.026 (0.083)\tData 0.000 (0.055)\tLoss 0.0884 (0.1118)\tPrec 96.094% (96.218%)\n",
      "Epoch: [71][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.1124 (0.1125)\tPrec 96.875% (96.164%)\n",
      "Epoch: [71][300/391]\tTime 0.025 (0.046)\tData 0.000 (0.019)\tLoss 0.0996 (0.1127)\tPrec 96.094% (96.151%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.626 (4.626)\tLoss 0.2446 (0.2446)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.900% \n",
      "best acc: 90.190000\n",
      "Epoch: [72][0/391]\tTime 5.628 (5.628)\tData 5.474 (5.474)\tLoss 0.1206 (0.1206)\tPrec 95.312% (95.312%)\n",
      "Epoch: [72][100/391]\tTime 0.027 (0.083)\tData 0.000 (0.055)\tLoss 0.1465 (0.1153)\tPrec 96.875% (96.148%)\n",
      "Epoch: [72][200/391]\tTime 0.025 (0.055)\tData 0.000 (0.028)\tLoss 0.1709 (0.1143)\tPrec 92.969% (96.160%)\n",
      "Epoch: [72][300/391]\tTime 0.026 (0.045)\tData 0.001 (0.019)\tLoss 0.0671 (0.1134)\tPrec 98.438% (96.151%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.631 (4.631)\tLoss 0.2765 (0.2765)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.940% \n",
      "best acc: 90.190000\n",
      "Epoch: [73][0/391]\tTime 5.549 (5.549)\tData 5.448 (5.448)\tLoss 0.1140 (0.1140)\tPrec 96.875% (96.875%)\n",
      "Epoch: [73][100/391]\tTime 0.034 (0.083)\tData 0.001 (0.054)\tLoss 0.1383 (0.1124)\tPrec 94.531% (96.094%)\n",
      "Epoch: [73][200/391]\tTime 0.026 (0.055)\tData 0.001 (0.027)\tLoss 0.1460 (0.1137)\tPrec 96.094% (96.063%)\n",
      "Epoch: [73][300/391]\tTime 0.027 (0.045)\tData 0.000 (0.018)\tLoss 0.0829 (0.1115)\tPrec 96.875% (96.151%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.637 (4.637)\tLoss 0.2624 (0.2624)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.820% \n",
      "best acc: 90.190000\n",
      "Epoch: [74][0/391]\tTime 5.818 (5.818)\tData 5.664 (5.664)\tLoss 0.1563 (0.1563)\tPrec 95.312% (95.312%)\n",
      "Epoch: [74][100/391]\tTime 0.025 (0.085)\tData 0.001 (0.056)\tLoss 0.1579 (0.1169)\tPrec 95.312% (96.109%)\n",
      "Epoch: [74][200/391]\tTime 0.025 (0.056)\tData 0.000 (0.029)\tLoss 0.1251 (0.1148)\tPrec 96.875% (96.129%)\n",
      "Epoch: [74][300/391]\tTime 0.026 (0.046)\tData 0.001 (0.019)\tLoss 0.1059 (0.1152)\tPrec 96.094% (96.086%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.636 (4.636)\tLoss 0.2384 (0.2384)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.980% \n",
      "best acc: 90.190000\n",
      "Epoch: [75][0/391]\tTime 5.552 (5.552)\tData 5.508 (5.508)\tLoss 0.1179 (0.1179)\tPrec 97.656% (97.656%)\n",
      "Epoch: [75][100/391]\tTime 0.026 (0.083)\tData 0.001 (0.055)\tLoss 0.0698 (0.1155)\tPrec 97.656% (96.163%)\n",
      "Epoch: [75][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.0827 (0.1144)\tPrec 95.312% (96.067%)\n",
      "Epoch: [75][300/391]\tTime 0.026 (0.046)\tData 0.000 (0.019)\tLoss 0.1836 (0.1140)\tPrec 92.969% (96.102%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.613 (4.613)\tLoss 0.2550 (0.2550)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.620% \n",
      "best acc: 90.190000\n",
      "Epoch: [76][0/391]\tTime 5.649 (5.649)\tData 5.466 (5.466)\tLoss 0.1438 (0.1438)\tPrec 96.875% (96.875%)\n",
      "Epoch: [76][100/391]\tTime 0.024 (0.084)\tData 0.000 (0.054)\tLoss 0.1020 (0.1106)\tPrec 96.094% (96.287%)\n",
      "Epoch: [76][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.0997 (0.1120)\tPrec 96.875% (96.226%)\n",
      "Epoch: [76][300/391]\tTime 0.027 (0.046)\tData 0.001 (0.019)\tLoss 0.1258 (0.1146)\tPrec 95.312% (96.120%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.618 (4.618)\tLoss 0.2906 (0.2906)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.740% \n",
      "best acc: 90.190000\n",
      "Epoch: [77][0/391]\tTime 5.505 (5.505)\tData 5.465 (5.465)\tLoss 0.0548 (0.0548)\tPrec 97.656% (97.656%)\n",
      "Epoch: [77][100/391]\tTime 0.024 (0.082)\tData 0.000 (0.054)\tLoss 0.0782 (0.1115)\tPrec 97.656% (96.078%)\n",
      "Epoch: [77][200/391]\tTime 0.024 (0.054)\tData 0.000 (0.027)\tLoss 0.0831 (0.1094)\tPrec 98.438% (96.253%)\n",
      "Epoch: [77][300/391]\tTime 0.028 (0.045)\tData 0.000 (0.018)\tLoss 0.1454 (0.1111)\tPrec 95.312% (96.120%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.646 (4.646)\tLoss 0.2796 (0.2796)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.840% \n",
      "best acc: 90.190000\n",
      "Epoch: [78][0/391]\tTime 5.659 (5.659)\tData 5.484 (5.484)\tLoss 0.0868 (0.0868)\tPrec 96.875% (96.875%)\n",
      "Epoch: [78][100/391]\tTime 0.026 (0.083)\tData 0.000 (0.055)\tLoss 0.1081 (0.1168)\tPrec 95.312% (95.978%)\n",
      "Epoch: [78][200/391]\tTime 0.025 (0.055)\tData 0.000 (0.028)\tLoss 0.1423 (0.1165)\tPrec 95.312% (95.977%)\n",
      "Epoch: [78][300/391]\tTime 0.025 (0.046)\tData 0.000 (0.019)\tLoss 0.1200 (0.1153)\tPrec 96.875% (95.985%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.612 (4.612)\tLoss 0.2799 (0.2799)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.840% \n",
      "best acc: 90.190000\n",
      "Epoch: [79][0/391]\tTime 5.651 (5.651)\tData 5.490 (5.490)\tLoss 0.0787 (0.0787)\tPrec 97.656% (97.656%)\n",
      "Epoch: [79][100/391]\tTime 0.025 (0.084)\tData 0.001 (0.055)\tLoss 0.0531 (0.1098)\tPrec 98.438% (96.148%)\n",
      "Epoch: [79][200/391]\tTime 0.025 (0.055)\tData 0.001 (0.028)\tLoss 0.1011 (0.1154)\tPrec 96.875% (96.059%)\n",
      "Epoch: [79][300/391]\tTime 0.028 (0.046)\tData 0.001 (0.019)\tLoss 0.0995 (0.1150)\tPrec 95.312% (96.016%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.624 (4.624)\tLoss 0.2460 (0.2460)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.820% \n",
      "best acc: 90.190000\n",
      "Epoch: [80][0/391]\tTime 5.623 (5.623)\tData 5.476 (5.476)\tLoss 0.1183 (0.1183)\tPrec 97.656% (97.656%)\n",
      "Epoch: [80][100/391]\tTime 0.025 (0.084)\tData 0.000 (0.055)\tLoss 0.0600 (0.1097)\tPrec 98.438% (96.194%)\n",
      "Epoch: [80][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.1100 (0.1114)\tPrec 95.312% (96.133%)\n",
      "Epoch: [80][300/391]\tTime 0.026 (0.046)\tData 0.000 (0.019)\tLoss 0.0664 (0.1119)\tPrec 96.875% (96.096%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.769 (4.769)\tLoss 0.2772 (0.2772)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.890% \n",
      "best acc: 90.190000\n",
      "Epoch: [81][0/391]\tTime 5.664 (5.664)\tData 5.481 (5.481)\tLoss 0.0836 (0.0836)\tPrec 96.875% (96.875%)\n",
      "Epoch: [81][100/391]\tTime 0.026 (0.084)\tData 0.002 (0.055)\tLoss 0.1351 (0.1045)\tPrec 96.094% (96.403%)\n",
      "Epoch: [81][200/391]\tTime 0.030 (0.055)\tData 0.000 (0.028)\tLoss 0.1530 (0.1066)\tPrec 94.531% (96.261%)\n",
      "Epoch: [81][300/391]\tTime 0.029 (0.046)\tData 0.000 (0.019)\tLoss 0.0798 (0.1113)\tPrec 98.438% (96.083%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.627 (4.627)\tLoss 0.2520 (0.2520)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.970% \n",
      "best acc: 90.190000\n",
      "Epoch: [82][0/391]\tTime 5.587 (5.587)\tData 5.474 (5.474)\tLoss 0.1762 (0.1762)\tPrec 94.531% (94.531%)\n",
      "Epoch: [82][100/391]\tTime 0.026 (0.083)\tData 0.000 (0.055)\tLoss 0.2005 (0.1137)\tPrec 92.188% (96.063%)\n",
      "Epoch: [82][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.0953 (0.1128)\tPrec 95.312% (96.148%)\n",
      "Epoch: [82][300/391]\tTime 0.024 (0.045)\tData 0.000 (0.019)\tLoss 0.1574 (0.1113)\tPrec 92.969% (96.257%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.669 (4.669)\tLoss 0.2747 (0.2747)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.810% \n",
      "best acc: 90.190000\n",
      "Epoch: [83][0/391]\tTime 5.550 (5.550)\tData 5.502 (5.502)\tLoss 0.1083 (0.1083)\tPrec 96.875% (96.875%)\n",
      "Epoch: [83][100/391]\tTime 0.024 (0.084)\tData 0.000 (0.055)\tLoss 0.1479 (0.1183)\tPrec 93.750% (95.939%)\n",
      "Epoch: [83][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.2122 (0.1152)\tPrec 92.188% (96.047%)\n",
      "Epoch: [83][300/391]\tTime 0.028 (0.046)\tData 0.000 (0.019)\tLoss 0.0560 (0.1155)\tPrec 99.219% (96.039%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.627 (4.627)\tLoss 0.2646 (0.2646)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.840% \n",
      "best acc: 90.190000\n",
      "Epoch: [84][0/391]\tTime 5.602 (5.602)\tData 5.477 (5.477)\tLoss 0.0787 (0.0787)\tPrec 97.656% (97.656%)\n",
      "Epoch: [84][100/391]\tTime 0.026 (0.084)\tData 0.001 (0.055)\tLoss 0.0986 (0.1179)\tPrec 96.094% (96.032%)\n",
      "Epoch: [84][200/391]\tTime 0.025 (0.055)\tData 0.000 (0.028)\tLoss 0.1435 (0.1152)\tPrec 92.188% (96.028%)\n",
      "Epoch: [84][300/391]\tTime 0.029 (0.046)\tData 0.001 (0.019)\tLoss 0.0881 (0.1138)\tPrec 96.094% (96.091%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.637 (4.637)\tLoss 0.2318 (0.2318)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.630% \n",
      "best acc: 90.190000\n",
      "Epoch: [85][0/391]\tTime 5.606 (5.606)\tData 5.470 (5.470)\tLoss 0.1264 (0.1264)\tPrec 94.531% (94.531%)\n",
      "Epoch: [85][100/391]\tTime 0.026 (0.084)\tData 0.001 (0.054)\tLoss 0.1268 (0.1126)\tPrec 96.094% (96.094%)\n",
      "Epoch: [85][200/391]\tTime 0.026 (0.055)\tData 0.000 (0.028)\tLoss 0.0806 (0.1143)\tPrec 96.875% (96.137%)\n",
      "Epoch: [85][300/391]\tTime 0.027 (0.046)\tData 0.000 (0.019)\tLoss 0.1043 (0.1110)\tPrec 95.312% (96.231%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.618 (4.618)\tLoss 0.2478 (0.2478)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.010% \n",
      "best acc: 90.190000\n",
      "Epoch: [86][0/391]\tTime 5.649 (5.649)\tData 5.457 (5.457)\tLoss 0.1259 (0.1259)\tPrec 95.312% (95.312%)\n",
      "Epoch: [86][100/391]\tTime 0.026 (0.082)\tData 0.000 (0.054)\tLoss 0.0734 (0.1066)\tPrec 97.656% (96.380%)\n",
      "Epoch: [86][200/391]\tTime 0.026 (0.055)\tData 0.001 (0.027)\tLoss 0.1361 (0.1121)\tPrec 95.312% (96.164%)\n",
      "Epoch: [86][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.019)\tLoss 0.1484 (0.1133)\tPrec 92.969% (96.138%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.614 (4.614)\tLoss 0.2457 (0.2457)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.960% \n",
      "best acc: 90.190000\n",
      "Epoch: [87][0/391]\tTime 5.632 (5.632)\tData 5.492 (5.492)\tLoss 0.1165 (0.1165)\tPrec 97.656% (97.656%)\n",
      "Epoch: [87][100/391]\tTime 0.025 (0.083)\tData 0.000 (0.055)\tLoss 0.0977 (0.1102)\tPrec 95.312% (96.225%)\n",
      "Epoch: [87][200/391]\tTime 0.026 (0.055)\tData 0.001 (0.028)\tLoss 0.0729 (0.1124)\tPrec 97.656% (96.210%)\n",
      "Epoch: [87][300/391]\tTime 0.027 (0.045)\tData 0.000 (0.019)\tLoss 0.1202 (0.1133)\tPrec 96.094% (96.120%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.616 (4.616)\tLoss 0.2752 (0.2752)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.860% \n",
      "best acc: 90.190000\n",
      "Epoch: [88][0/391]\tTime 5.526 (5.526)\tData 5.418 (5.418)\tLoss 0.1890 (0.1890)\tPrec 93.750% (93.750%)\n",
      "Epoch: [88][100/391]\tTime 0.026 (0.082)\tData 0.001 (0.054)\tLoss 0.1159 (0.1132)\tPrec 96.875% (96.194%)\n",
      "Epoch: [88][200/391]\tTime 0.024 (0.054)\tData 0.000 (0.027)\tLoss 0.1038 (0.1126)\tPrec 96.875% (96.280%)\n",
      "Epoch: [88][300/391]\tTime 0.027 (0.045)\tData 0.001 (0.018)\tLoss 0.1001 (0.1108)\tPrec 96.875% (96.283%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.670 (4.670)\tLoss 0.2598 (0.2598)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.690% \n",
      "best acc: 90.190000\n",
      "Epoch: [89][0/391]\tTime 6.026 (6.026)\tData 5.884 (5.884)\tLoss 0.0744 (0.0744)\tPrec 98.438% (98.438%)\n",
      "Epoch: [89][100/391]\tTime 0.028 (0.088)\tData 0.000 (0.059)\tLoss 0.2612 (0.1123)\tPrec 89.844% (95.985%)\n",
      "Epoch: [89][200/391]\tTime 0.026 (0.058)\tData 0.001 (0.030)\tLoss 0.0978 (0.1119)\tPrec 96.875% (96.121%)\n",
      "Epoch: [89][300/391]\tTime 0.028 (0.047)\tData 0.001 (0.020)\tLoss 0.1065 (0.1131)\tPrec 96.094% (96.135%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.702 (4.702)\tLoss 0.2184 (0.2184)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.880% \n",
      "best acc: 90.190000\n",
      "Epoch: [90][0/391]\tTime 5.600 (5.600)\tData 5.550 (5.550)\tLoss 0.1001 (0.1001)\tPrec 97.656% (97.656%)\n",
      "Epoch: [90][100/391]\tTime 0.026 (0.085)\tData 0.000 (0.055)\tLoss 0.1036 (0.1066)\tPrec 96.875% (96.341%)\n",
      "Epoch: [90][200/391]\tTime 0.028 (0.056)\tData 0.000 (0.028)\tLoss 0.0640 (0.1071)\tPrec 97.656% (96.300%)\n",
      "Epoch: [90][300/391]\tTime 0.026 (0.046)\tData 0.001 (0.019)\tLoss 0.1268 (0.1075)\tPrec 97.656% (96.320%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.634 (4.634)\tLoss 0.2666 (0.2666)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.860% \n",
      "best acc: 90.190000\n",
      "Epoch: [91][0/391]\tTime 5.610 (5.610)\tData 5.472 (5.472)\tLoss 0.0848 (0.0848)\tPrec 98.438% (98.438%)\n",
      "Epoch: [91][100/391]\tTime 0.047 (0.083)\tData 0.001 (0.054)\tLoss 0.1275 (0.1158)\tPrec 93.750% (95.893%)\n",
      "Epoch: [91][200/391]\tTime 0.025 (0.055)\tData 0.001 (0.028)\tLoss 0.0959 (0.1150)\tPrec 96.875% (95.993%)\n",
      "Epoch: [91][300/391]\tTime 0.026 (0.045)\tData 0.000 (0.019)\tLoss 0.0898 (0.1136)\tPrec 96.875% (96.031%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.637 (4.637)\tLoss 0.2475 (0.2475)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.800% \n",
      "best acc: 90.190000\n",
      "Epoch: [92][0/391]\tTime 5.636 (5.636)\tData 5.483 (5.483)\tLoss 0.1111 (0.1111)\tPrec 96.094% (96.094%)\n",
      "Epoch: [92][100/391]\tTime 0.026 (0.083)\tData 0.000 (0.055)\tLoss 0.1116 (0.1236)\tPrec 94.531% (95.730%)\n",
      "Epoch: [92][200/391]\tTime 0.025 (0.055)\tData 0.000 (0.028)\tLoss 0.1726 (0.1170)\tPrec 93.750% (95.997%)\n",
      "Epoch: [92][300/391]\tTime 0.027 (0.046)\tData 0.001 (0.019)\tLoss 0.1362 (0.1142)\tPrec 94.531% (96.127%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.654 (4.654)\tLoss 0.2660 (0.2660)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.940% \n",
      "best acc: 90.190000\n",
      "Epoch: [93][0/391]\tTime 5.526 (5.526)\tData 5.477 (5.477)\tLoss 0.2321 (0.2321)\tPrec 92.188% (92.188%)\n",
      "Epoch: [93][100/391]\tTime 0.026 (0.083)\tData 0.000 (0.055)\tLoss 0.2134 (0.1186)\tPrec 91.406% (95.985%)\n",
      "Epoch: [93][200/391]\tTime 0.025 (0.055)\tData 0.001 (0.028)\tLoss 0.0881 (0.1168)\tPrec 95.312% (95.985%)\n",
      "Epoch: [93][300/391]\tTime 0.029 (0.045)\tData 0.001 (0.019)\tLoss 0.1326 (0.1170)\tPrec 95.312% (95.985%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.609 (4.609)\tLoss 0.3325 (0.3325)\tPrec 90.625% (90.625%)\n",
      " * Prec 90.150% \n",
      "best acc: 90.190000\n",
      "Epoch: [94][0/391]\tTime 5.629 (5.629)\tData 5.494 (5.494)\tLoss 0.1308 (0.1308)\tPrec 96.094% (96.094%)\n",
      "Epoch: [94][100/391]\tTime 0.028 (0.083)\tData 0.000 (0.055)\tLoss 0.1523 (0.1107)\tPrec 94.531% (96.187%)\n",
      "Epoch: [94][200/391]\tTime 0.029 (0.056)\tData 0.001 (0.028)\tLoss 0.1004 (0.1101)\tPrec 96.875% (96.249%)\n",
      "Epoch: [94][300/391]\tTime 0.028 (0.046)\tData 0.000 (0.019)\tLoss 0.0928 (0.1101)\tPrec 96.094% (96.286%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.625 (4.625)\tLoss 0.2777 (0.2777)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.980% \n",
      "best acc: 90.190000\n",
      "Epoch: [95][0/391]\tTime 5.620 (5.620)\tData 5.597 (5.597)\tLoss 0.1758 (0.1758)\tPrec 93.750% (93.750%)\n",
      "Epoch: [95][100/391]\tTime 0.025 (0.082)\tData 0.000 (0.056)\tLoss 0.0850 (0.1051)\tPrec 96.094% (96.349%)\n",
      "Epoch: [95][200/391]\tTime 0.031 (0.054)\tData 0.000 (0.028)\tLoss 0.0923 (0.1100)\tPrec 96.875% (96.191%)\n",
      "Epoch: [95][300/391]\tTime 0.027 (0.045)\tData 0.001 (0.019)\tLoss 0.1064 (0.1115)\tPrec 96.094% (96.156%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.633 (4.633)\tLoss 0.2373 (0.2373)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.040% \n",
      "best acc: 90.190000\n",
      "Epoch: [96][0/391]\tTime 5.606 (5.606)\tData 5.469 (5.469)\tLoss 0.0396 (0.0396)\tPrec 98.438% (98.438%)\n",
      "Epoch: [96][100/391]\tTime 0.026 (0.083)\tData 0.000 (0.055)\tLoss 0.2049 (0.1100)\tPrec 92.188% (96.287%)\n",
      "Epoch: [96][200/391]\tTime 0.031 (0.054)\tData 0.000 (0.028)\tLoss 0.0615 (0.1135)\tPrec 98.438% (96.090%)\n",
      "Epoch: [96][300/391]\tTime 0.026 (0.045)\tData 0.001 (0.019)\tLoss 0.0510 (0.1129)\tPrec 98.438% (96.099%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.632 (4.632)\tLoss 0.2805 (0.2805)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.840% \n",
      "best acc: 90.190000\n",
      "Epoch: [97][0/391]\tTime 5.552 (5.552)\tData 5.426 (5.426)\tLoss 0.0839 (0.0839)\tPrec 98.438% (98.438%)\n",
      "Epoch: [97][100/391]\tTime 0.026 (0.082)\tData 0.000 (0.054)\tLoss 0.0344 (0.1130)\tPrec 100.000% (96.125%)\n",
      "Epoch: [97][200/391]\tTime 0.026 (0.054)\tData 0.001 (0.027)\tLoss 0.1269 (0.1130)\tPrec 95.312% (96.102%)\n",
      "Epoch: [97][300/391]\tTime 0.025 (0.045)\tData 0.000 (0.018)\tLoss 0.0977 (0.1113)\tPrec 96.094% (96.185%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.598 (4.598)\tLoss 0.3050 (0.3050)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.930% \n",
      "best acc: 90.190000\n",
      "Epoch: [98][0/391]\tTime 5.569 (5.569)\tData 5.451 (5.451)\tLoss 0.0630 (0.0630)\tPrec 99.219% (99.219%)\n",
      "Epoch: [98][100/391]\tTime 0.031 (0.082)\tData 0.000 (0.054)\tLoss 0.0458 (0.1115)\tPrec 98.438% (96.109%)\n",
      "Epoch: [98][200/391]\tTime 0.026 (0.054)\tData 0.001 (0.028)\tLoss 0.0527 (0.1097)\tPrec 99.219% (96.253%)\n",
      "Epoch: [98][300/391]\tTime 0.028 (0.045)\tData 0.000 (0.019)\tLoss 0.1361 (0.1125)\tPrec 95.312% (96.164%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.590 (4.590)\tLoss 0.2455 (0.2455)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.870% \n",
      "best acc: 90.190000\n",
      "Epoch: [99][0/391]\tTime 5.570 (5.570)\tData 5.438 (5.438)\tLoss 0.0946 (0.0946)\tPrec 96.094% (96.094%)\n",
      "Epoch: [99][100/391]\tTime 0.026 (0.082)\tData 0.000 (0.054)\tLoss 0.1178 (0.1099)\tPrec 95.312% (96.101%)\n",
      "Epoch: [99][200/391]\tTime 0.032 (0.054)\tData 0.000 (0.027)\tLoss 0.1043 (0.1113)\tPrec 96.094% (96.133%)\n",
      "Epoch: [99][300/391]\tTime 0.024 (0.045)\tData 0.000 (0.018)\tLoss 0.0835 (0.1117)\tPrec 97.656% (96.125%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 4.602 (4.602)\tLoss 0.2605 (0.2605)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.610% \n",
      "best acc: 90.190000\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "weight_decay = 4e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# weight decay: for regularization to prevent overfitting\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')   \n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    \n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_7872\\564645170.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9019/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        #print(layer,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_q = model.features[27].weight_q\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "#print(weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = save_output.outputs[8][0]\n",
    "act_alpha  = model.features[27].act_alpha\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "#print(act_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "victorian-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell is provided\n",
    "\n",
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "conv_int.bias = model.features[27].bias\n",
    "output_int = conv_int(act_int)\n",
    "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))\n",
    "output_recovered = torch.relu(output_recovered)\n",
    "#print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSUM recovered error:\n",
      "3.2451487186335726e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"PSUM recovered error:\")\n",
    "print(abs((save_output.outputs[9][0] - output_recovered)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "subsequent-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# act_int.size = torch.Size([128, 64, 32, 32])  <- batch_size, input_ch, ni, nj\n",
    "a_int = act_int[0,:,:,:]  # pick only one input out of batch\n",
    "# a_int.size() = [64, 32, 32]\n",
    "\n",
    "# conv_int.weight.size() = torch.Size([64, 64, 3, 3])  <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "# w_int.weight.size() = torch.Size([64, 64, 9])\n",
    "                      \n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8 # row and column number\n",
    "\n",
    "nig = range(a_int.size(1))  ## ni group\n",
    "njg = range(a_int.size(2))  ## nj group\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "ic_tileg = range(int(len(icg)/array_size))\n",
    "oc_tileg = range(int(len(ocg)/array_size))\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "######## Padding before Convolution #######\n",
    "a_pad = torch.zeros(len(icg), len(nig)+padding*2, len(nig)+padding*2).cuda()\n",
    "# a_pad.size() = [64, 32+2pad, 32+2pad]\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "# a_pad.size() = [64, (32+2pad)*(32+2pad)]\n",
    "\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1)) # merge ki, kj index to kij\n",
    "\n",
    "###########################################\n",
    "\n",
    "p_nijg = range(a_pad.size(1)) ## psum nij group\n",
    "\n",
    "psum = torch.zeros( array_size, len(p_nijg), len(kijg)).cuda() \n",
    "\n",
    "for kij in kijg:\n",
    "    for nij in p_nijg:       # time domain, sequentially given input\n",
    "        m = nn.Linear(array_size, array_size, bias=False)\n",
    "        #m.weight = torch.nn.Parameter(w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, kij])\n",
    "        m.weight = torch.nn.Parameter(w_int[:,:,kij])\n",
    "        psum[:, nij, kij] = m(a_pad[:,nij]).cuda()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1)\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:\n",
    "        out[:, o_nij] = out[:, o_nij] + \\\n",
    "        psum[ :, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 4th index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0729e-05, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_2D = torch.reshape(out, (out.size(0), o_ni_dim, -1))\n",
    "difference = (out_2D - output_int[0,:,:,:])\n",
    "print(difference.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "endangered-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show this cell partially. The following cells should be printed by students ###\n",
    "\n",
    "X = a_pad[:,:]  # [array row num, time_steps] only 36 values in an image at this layer\n",
    "bit_precision = 4\n",
    "file = open('activation.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(round(X[7-j,i].item()))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "accomplished-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "kij = range(w_int.size(2))\n",
    "\n",
    "bit_precision = 4\n",
    "for k in kij:\n",
    "    W = w_int[:,:,k]  # w_tile[tile_num, array col num, array row num, kij]\n",
    "    file = open('weight_kij{}.txt'.format(k), 'w') #write to file\n",
    "    file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "    file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "\n",
    "    for i in range(W.size(0)):  # col #\n",
    "        for j in range(W.size(1)): # row #\n",
    "            temp=round(W[i,j].item())\n",
    "            if(temp < 0 ):\n",
    "                temp=temp+16\n",
    "            W_bin = '{0:04b}'.format(temp)\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "    file.close() #close file   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "coastal-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0000,  3.0000, -4.0000,  2.0000,  4.0000, -1.0000, -2.0000, -4.0000],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0,:] # check this number with your 2nd line in weight.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5f83f",
   "metadata": {},
   "source": [
    "## PSUM writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "stupid-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "\n",
    "bit_precision = 16\n",
    "\n",
    "for k in range(psum.size(2)):\n",
    "    file = open('psum_kij{}.txt'.format(k), 'w') #write to file\n",
    "    file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "    file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "    for i in range(psum.size(1)):  # nijg #\n",
    "        for j in range(psum.size(0)): # row #\n",
    "            temp=round(psum[j,i,k].item())\n",
    "            if(temp < 0 ):\n",
    "                temp=temp+65536\n",
    "            W_bin = '{0:016b}'.format(temp)\n",
    "            for b in range(bit_precision):\n",
    "                file.write(W_bin[b])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "    file.close() #close file   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b385fd",
   "metadata": {},
   "source": [
    "## Output Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8680fa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4140e+00],\n",
      "          [0.0000e+00, 2.8163e+00, 3.0175e+00, 3.8221e+00],\n",
      "          [2.2128e+00, 3.3192e+00, 4.0233e+00, 9.0524e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.8105e+00, 7.0408e-01, 1.5087e+00, 2.5146e+00],\n",
      "          [1.1921e-07, 0.0000e+00, 1.7099e+00, 0.0000e+00],\n",
      "          [2.0117e-01, 0.0000e+00, 0.0000e+00, 5.0291e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0291e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1122e+00],\n",
      "          [1.1064e+00, 4.7274e+00, 3.7216e+00, 2.3134e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.0350e-01, 2.8163e+00, 5.2303e+00, 5.1297e+00],\n",
      "          [3.2186e+00, 4.5262e+00, 7.7449e+00, 3.3192e+00],\n",
      "          [4.6268e+00, 4.0233e+00, 4.1239e+00, 6.0350e-01],\n",
      "          [1.5087e+00, 1.0058e-01, 4.0233e-01, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.0058e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4082e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.0524e-01, 2.7157e+00, 1.7099e+00, 2.7157e+00],\n",
      "          [3.0175e-01, 1.5087e+00, 1.5087e+00, 3.2186e+00],\n",
      "          [0.0000e+00, 2.2128e+00, 4.2245e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3076e+00, 6.0350e-01, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 1.0058e+00, 0.0000e+00, 2.0117e-01],\n",
      "          [0.0000e+00, 1.0058e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.4082e+00, 3.0175e-01, 1.0058e-01, 2.0117e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[2.4140e+00, 3.4198e+00, 7.9460e+00, 4.5262e+00],\n",
      "          [7.1414e+00, 1.1969e+01, 1.5289e+01, 1.2673e+01],\n",
      "          [1.2573e+01, 1.8306e+01, 2.0619e+01, 1.4685e+01],\n",
      "          [9.9577e+00, 1.2875e+01, 1.1668e+01, 7.0408e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.2070e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 2.0117e+00, 4.4256e+00, 3.9227e+00],\n",
      "          [5.8338e+00, 1.1768e+01, 5.9344e+00, 1.0058e+00],\n",
      "          [8.8513e+00, 1.0461e+01, 4.1239e+00, 1.0058e-01],\n",
      "          [0.0000e+00, 5.0291e-01, 0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 2.2128e+00, 1.5087e+00, 1.9111e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.1122e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.0233e-01, 1.3076e+00]],\n",
      "\n",
      "         [[0.0000e+00, 2.0116e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [2.0117e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0466e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.1181e+00, 4.6268e+00, 9.7565e+00, 2.9169e+00],\n",
      "          [6.1355e+00, 9.7565e+00, 1.4584e+01, 8.2478e+00],\n",
      "          [6.4373e+00, 1.0963e+01, 1.9614e+01, 1.2673e+01],\n",
      "          [4.9285e+00, 8.4489e+00, 9.9577e+00, 3.6210e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.9111e+00, 1.1064e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.2128e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.6093e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.1064e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.0117e-01, 0.0000e+00, 0.0000e+00, 6.0350e-01]],\n",
      "\n",
      "         [[0.0000e+00, 7.0408e-01, 0.0000e+00, 4.7274e+00],\n",
      "          [3.8221e+00, 5.6326e+00, 7.0408e-01, 2.7157e+00],\n",
      "          [4.6268e+00, 7.6443e+00, 2.4140e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.6210e+00, 2.3134e+00, 2.1122e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.0117e-01, 5.0291e-01, 0.0000e+00, 2.0116e-01],\n",
      "          [3.0175e-01, 4.3250e+00, 2.1122e+00, 1.6093e+00],\n",
      "          [0.0000e+00, 7.3425e+00, 5.6326e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.0408e-01, 0.0000e+00, 0.0000e+00, 1.6093e+00],\n",
      "          [1.3076e+00, 0.0000e+00, 0.0000e+00, 8.0466e-01],\n",
      "          [1.1064e+00, 0.0000e+00, 1.0058e+00, 4.1239e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[2.1122e+00, 0.0000e+00, 2.2128e+00, 0.0000e+00],\n",
      "          [2.7157e+00, 1.6093e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.0291e+00, 1.1668e+01, 8.2478e+00, 0.0000e+00],\n",
      "          [6.0350e-01, 8.1472e+00, 7.2419e+00, 2.0117e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.4082e+00, 0.0000e+00, 7.0408e-01, 1.0058e+00],\n",
      "          [1.9111e+00, 1.2070e+00, 2.7157e+00, 0.0000e+00],\n",
      "          [2.0117e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [7.7449e+00, 8.3484e+00, 6.3367e+00, 2.1122e+00]],\n",
      "\n",
      "         [[3.0175e-01, 1.5087e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.2070e+00, 4.0233e-01, 4.0233e-01, 2.6151e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6210e+00],\n",
      "          [0.0000e+00, 2.5146e+00, 2.4140e+00, 1.8105e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 1.8105e+00, 5.7332e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 4.0233e+00, 3.5204e+00],\n",
      "          [0.0000e+00, 3.1181e+00, 4.7274e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.7099e+00, 1.5087e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8105e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 1.2070e+00, 3.0175e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[4.0233e+00, 7.8454e+00, 9.8571e+00, 8.9518e+00],\n",
      "          [8.5495e+00, 1.6797e+01, 1.6596e+01, 1.3579e+01],\n",
      "          [4.3251e+00, 1.2573e+01, 1.2271e+01, 6.9402e+00],\n",
      "          [1.1064e+00, 6.0350e-01, 1.8105e+00, 2.6151e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.1122e+00, 5.0291e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.8105e+00, 2.0117e-01, 1.9111e+00, 8.0466e-01],\n",
      "          [1.0058e+00, 2.4140e+00, 2.3134e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.2128e+00, 1.6093e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[2.0117e-01, 3.6210e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 6.0350e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.6093e+00, 7.8454e+00, 3.9227e+00, 3.6210e+00],\n",
      "          [1.0058e+00, 4.1239e+00, 4.3251e+00, 2.8163e+00]],\n",
      "\n",
      "         [[9.0524e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.9169e+00, 2.4140e+00, 4.0233e-01],\n",
      "          [0.0000e+00, 3.0175e-01, 5.6326e+00, 2.4140e+00],\n",
      "          [2.3134e+00, 1.8105e+00, 1.4082e+00, 1.0058e-01]],\n",
      "\n",
      "         [[9.0524e-01, 1.2070e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.8105e+00, 2.2128e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.0524e-01, 5.9605e-08, 3.0175e-01, 0.0000e+00],\n",
      "          [1.4082e+00, 2.2128e+00, 2.7157e+00, 5.9605e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.4140e+00, 2.1122e+00, 5.0291e+00, 4.3251e+00],\n",
      "          [5.1297e+00, 8.1472e+00, 9.7565e+00, 4.2245e+00],\n",
      "          [2.5146e+00, 5.9344e+00, 5.6326e+00, 2.0117e+00],\n",
      "          [0.0000e+00, 4.0233e-01, 1.4082e+00, 5.0291e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.5204e+00, 2.1122e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.9111e+00, 9.0524e-01, 1.9111e+00],\n",
      "          [2.3134e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 6.0350e-01, 1.6093e+00],\n",
      "          [4.0233e-01, 0.0000e+00, 0.0000e+00, 1.0058e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 1.6093e+00, 4.0233e-01],\n",
      "          [0.0000e+00, 1.8105e+00, 1.0058e+00, 0.0000e+00]]]], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):  \u001b[38;5;66;03m# nijg #\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)): \u001b[38;5;66;03m# row #\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m         temp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m(\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(temp \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m ):\n\u001b[0;32m     11\u001b[0m             temp\u001b[38;5;241m=\u001b[39mtemp\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m65536\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "bit_precision = 16\n",
    "print(save_output.outputs[9][0])\n",
    "file = open('out.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "for i in range(out.size(1)):  # nijg #\n",
    "    for j in range(out.size(0)): # row #\n",
    "        temp=round(out[j,i,k].item())\n",
    "        if(temp < 0 ):\n",
    "            temp=temp+65536\n",
    "        W_bin = '{0:016b}'.format(temp)\n",
    "        for b in range(bit_precision):\n",
    "            file.write(W_bin[b])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
